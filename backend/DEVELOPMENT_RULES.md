# iloveresume 개발 규칙

## 프로젝트 개요
- **목적**: AI 기반 자기소개서 생성 서비스
- **기술 스택**: Flask (백엔드), React (프론트엔드), Google Vertex AI Gemini 2.0 Flash
- **데이터베이스**: SQLite + SQLAlchemy + Alembic

## 핵심 원칙

### 비용 최적화
1. **AI 모델 호출 최소화**: 1회 사용당 1회의 모델 호출만 허용 (배치 처리)
2. **OCR 최적화**: 텍스트가 충분한 경우 OCR 건너뛰기
3. **단일 이미지 OCR**: OCR 실행 시 가장 관련성 높은 단 하나의 이미지만 선별하여 처리

### 지원 사이트 정책
1. **링커리어 차단**: `https://linkareer.com/` 또는 `http://linkareer.com/`로 시작하는 URL은 차단
   - 사용자에게 "링커리어 채용공고는 아직 지원하지 않아요." 메시지 표시
   - HTTP 400 상태 코드 반환

2. **하이브리드 URL 검증 시스템**: 모든 채용공고 사이트 지원
   - **1단계**: 주요 플랫폼 URL 패턴 검사 (원티드, 사람인, 프로그래머스 등)
   - **2단계**: 일반 키워드 URL 패턴 검사 (careers, jobs, recruit 등)
   - **3단계**: 웹 크롤링 및 콘텐츠 분석 (JSON-LD 스키마, 키워드 분석)
   - 기업 자체 채용공고 페이지도 지원

## 채용공고 직무 추출 시스템 (간소화된 7단계 로직)

### 기존 복잡한 시스템 폐지
- 기존의 복잡한 구조화 및 키워드 매칭 방식 폐지
- 페이지 제목 위주의 직관적인 접근 방식으로 대체

### 새로운 7단계 추출 과정
1. **Selenium 동적 페이지 로드**: JavaScript 렌더링 완료 후 HTML 확보
2. **콘텐츠 분석 및 채용공고 검증**: JSON-LD 스키마, 키워드 분석으로 채용공고 여부 판단
3. **BeautifulSoup 구조적 클리닝**: 불필요한 태그 제거 및 텍스트 정제
4. **텍스트 유효성 분석**: 구조적 완성도 기반 품질 점수 시스템으로 OCR 실행 여부 결정
5. **조건부 OCR 실행**: 텍스트 부족 시에만 실행, 가장 큰 이미지 1개만 처리
6. **콘텐츠 통합**: 텍스트 + OCR 결과 통합 (OCR 결과물 우선 원칙)
7. **페이지 제목 기반 직무 추출**: 휴리스틱 점수 모델로 최고 후보 단일 직무 제목 선정

### 직무 추출 시스템 (휴리스틱 점수 기반)
- **최고 후보 선정**: 모든 후보 중 점수가 가장 높은 단일 직무 제목만 선택
- **다각도 점수 평가**: 태그 중요도, 클래스명, DOM 순서, 부정 키워드 등 종합 평가
- **강화된 정제**: 회사명, 꼬리표, 불필요한 접미사 자동 제거
- **최소 점수 기준**: 25점 미만 후보는 무효로 판단하여 "직무 정보 없음" 반환

### 점수 부여 규칙
- **태그 중요도**: h1(50점) > title(30점) > h2(20점)
- **클래스명 보너스**: job-title, position-title 등 명확한 클래스에 100점 추가
- **DOM 순서**: 문서 앞부분에 나올수록 최대 10점 가산
- **부정 키워드**: careers, cookie, © 등 직무와 무관한 키워드에 30점 감점
- **괄호 보너스**: [회사명], (경력) 등에 5점 가산

### 직무 추출 시스템 (페이지 제목 위주)
- **HTML title 태그**: 페이지의 메인 제목 추출
- **h1 태그들**: 주요 제목들 (200자 미만으로 제한)
- **h2 태그들**: 보조 제목들 (100자 미만으로 제한)
- **제목 정제**: 회사명, 불필요한 접미사 제거
- **길이 제한**: 5자~100자 범위의 제목만 유효
- **최대 3개**: 중복 제거 후 최대 3개까지만 반환

### 핵심 간소화 원칙
- **직관적 접근**: 사용자가 보는 페이지 제목 그대로 추출
- **구조화 제거**: 복잡한 섹션 분리 과정 완전 제거
- **키워드 목록 제거**: 방대한 직무 키워드 데이터베이스 폐지
- **단순한 필터링**: 기본적인 길이 및 형식 검증만 수행

### 구조적 완성도 기반 OCR 실행 로직
- **품질 점수 시스템**: 단순 키워드 카운트 대신 구조적 완성도 평가
- **핵심 섹션 조합**: '주요업무' + '자격요건' 동시 존재 시 높은 가중치
- **보너스 섹션**: '우대사항', '채용절차' 등 추가 섹션에 보너스 점수
- **임계점 기준**: 3점 이상이면 텍스트 충분, 미만이면 OCR 실행
- **정확한 판단**: 회사 소개나 목록 페이지와 실제 채용공고 구분

### 장점
- **단순성**: 복잡한 로직 제거로 유지보수 용이
- **직관성**: 페이지에 표시된 제목 그대로 추출
- **빠른 처리**: 불필요한 텍스트 분석 과정 제거
- **높은 신뢰성**: 페이지 제목은 가장 확실한 정보
- **확장성**: 다양한 사이트 구조에 범용적으로 적용 가능

## Error Handling
- **APIError**: 사용자 정의 API 오류 클래스
- **ValidationError**: 데이터 검증 오류
- **FileProcessingError**: 파일 처리 오류
- **ChromeDriverError**: 브라우저 드라이버 오류

## API Design
- **RESTful 구조**: 표준 HTTP 메서드 사용
- **일관된 응답 형식**: JSON 기반 통일된 응답 구조
- **상태 코드 활용**: 적절한 HTTP 상태 코드 반환
- **에러 메시지**: 사용자 친화적인 오류 메시지

## Environment Variables
- **DATABASE_URL**: 데이터베이스 연결 문자열
- **PROJECT_ID**: GCP 프로젝트 ID
- **LOCATION**: Vertex AI 리전 (us-central1)
- **CORS_ORIGINS**: 허용된 프론트엔드 도메인
- **LOG_LEVEL**: 로깅 레벨 설정
- **CHROME_DRIVER_PATH**: ChromeDriver 수동 경로 (선택사항)

## Code Quality
- **모듈화**: 기능별 서비스 분리 (AIService, CrawlingService, OCRService, FileService)
- **설정 분리**: config 모듈로 환경 변수 관리
- **유틸리티 분리**: utils 모듈로 공통 기능 관리
- **로깅**: 구조화된 로깅 시스템
- **타입 힌트**: Python 타입 힌트 활용
- **예외 처리**: 적절한 예외 처리 및 오류 전파

## 개발 시 주의사항

### AI 모델 사용
- **배치 처리**: 여러 질문을 한 번에 처리하여 모델 호출 최소화
- **응답 파싱**: AI 응답의 구조화된 파싱 필수
- **오류 처리**: 모델 호출 실패 시 적절한 fallback

### ChromeDriver 관리
- **다중 전략**: webdriver-manager, 수동 경로, 시스템 PATH 순서로 시도
- **Fallback**: ChromeDriver 실패 시 requests + BeautifulSoup 사용
- **Windows 호환성**: Windows 환경에서의 ChromeDriver 경로 설정

### 파일 처리
- **보안**: 업로드 파일 타입 및 크기 검증
- **성능**: 대용량 파일 처리 시 메모리 효율성 고려
- **정리**: 임시 파일 자동 삭제

### 데이터베이스
- **마이그레이션**: Alembic을 통한 스키마 변경 관리
- **트랜잭션**: 데이터 일관성을 위한 트랜잭션 처리
- **연결 관리**: 데이터베이스 연결 풀 관리

## 테스트 및 검증
- **Mock API**: 개발 환경에서의 API 모킹
- **단위 테스트**: 각 서비스별 독립적 테스트
- **통합 테스트**: 전체 워크플로우 테스트
- **성능 테스트**: 대용량 데이터 처리 성능 검증 